{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qQCtVynVJFLP"
      },
      "outputs": [],
      "source": [
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import copy\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from google.protobuf.json_format import MessageToDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZCpD4L06JIl4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E4Gnfu6EcelQ"
      },
      "outputs": [],
      "source": [
        "SavedModel = keras.models.load_model('path_to_model') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Capturing hands in real time for predicting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "VyCbo791gRC2",
        "outputId": "a6475c9b-65dd-4a04-eed5-c5863c1a7058"
      },
      "outputs": [],
      "source": [
        "#Some of the functions we'll be using\n",
        "def get_bbox_coordinates(handLadmark, image_shape):\n",
        "    \n",
        "    all_x, all_y = [], [] # store all x and y points in list\n",
        "    for hnd in mp_hands.HandLandmark:\n",
        "        all_x.append(int(handLadmark.landmark[hnd].x * image_shape[1])) # multiply x by image width\n",
        "        all_y.append(int(handLadmark.landmark[hnd].y * image_shape[0])) # multiply y by image height\n",
        "\n",
        "    return min(all_x), min(all_y), max(all_x), max(all_y) # return as (xmin, ymin, xmax, ymax)\n",
        "\n",
        "def return_letter(array):\n",
        "    if(array[0][0].any()==1):\n",
        "        return('A')\n",
        "    elif(array[0][1].any()==1):\n",
        "        return('B')\n",
        "    elif(array[0][2].any()==1):\n",
        "        return('C')\n",
        "    elif(array[0][3].any()==1):\n",
        "        return('D')\n",
        "    elif(array[0][4].any()==1):\n",
        "        return('E')\n",
        "    elif(array[0][5].any()==1):\n",
        "        return('F')\n",
        "    elif(array[0][6].any()==1):\n",
        "        return('G')\n",
        "    elif(array[0][7].any()==1):\n",
        "        return('H')\n",
        "    elif(array[0][8].any()==1):\n",
        "        return('I')\n",
        "    elif(array[0][9].any()==1):\n",
        "        return('J')\n",
        "    elif(array[0][10].any()==1):\n",
        "        return('K')\n",
        "    elif(array[0][11].any()==1):\n",
        "        return('L')\n",
        "    elif(array[0][12].any()==1):\n",
        "        return('M')\n",
        "    elif(array[0][13].any()==1):\n",
        "        return('N')\n",
        "    elif(array[0][14].any()==1):\n",
        "        return('O')\n",
        "    elif(array[0][15].any()==1):\n",
        "        return('P')\n",
        "    elif(array[0][16].any()==1):\n",
        "        return('Q')\n",
        "    elif(array[0][17].any()==1):\n",
        "        return('R')\n",
        "    elif(array[0][18].any()==1):\n",
        "        return('S')\n",
        "    elif(array[0][19].any()==1):\n",
        "        return('T')\n",
        "    elif(array[0][20].any()==1):\n",
        "        return('U')\n",
        "    elif(array[0][21].any()==1):\n",
        "        return('V')\n",
        "    elif(array[0][22].any()==1):\n",
        "        return('W')\n",
        "    elif(array[0][23].any()==1):\n",
        "        return('x')\n",
        "    elif(array[0][24].any()==1):\n",
        "        return('Y')\n",
        "    else:\n",
        "        return('Z')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 1\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "_, frame = cap.read()\n",
        "h, w, c = frame.shape\n",
        "\n",
        "with mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5) as hands:\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            print(\"Ignoring empty camera frame.\")\n",
        "            continue\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = hands.process(image)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "            \n",
        "        if results.multi_hand_landmarks:\n",
        "            brect = []\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                brect.append(get_bbox_coordinates(hand_landmarks, (h, w)))\n",
        "                    \n",
        "            if len(brect)==1:\n",
        "                cv2.rectangle(image, (brect[0][0]-35, brect[0][1]-35), (brect[0][2]+35, brect[0][3]+35), (0, 255, 0), 2)\n",
        "                roi = image[brect[0][1]-35:brect[0][3]+35, brect[0][0]-35:brect[0][2]+35]\n",
        "                roi = cv2.flip(cv2.resize(roi, (128,128)), 1)\n",
        "                prediction = SavedModel.predict(roi.reshape(1, 128, 128, 3))\n",
        "                pred_array = np.int8(prediction == prediction.max())\n",
        "                cv2.putText(image, return_letter(pred_array), (125, 50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (0,0,0), 2)\n",
        "                # print(pred_array)\n",
        "\n",
        "            if len(brect)>1:\n",
        "                cv2.rectangle(image, (min(brect[0][0], brect[1][0])-35, (min(brect[0][1], brect[1][1]))-35), (max(brect[0][2], brect[1][2])+35, (max(brect[0][3], brect[1][3]))+35), (0, 255, 0), 2)\n",
        "                roi = image[min(brect[0][1], brect[1][1])-35:max(brect[0][3], brect[1][3])+35, min(brect[0][0], brect[1][0])-35:max(brect[0][2], brect[1][2])+35]\n",
        "                roi = cv2.flip(cv2.resize(roi, (128,128)), 1)\n",
        "                prediction = SavedModel.predict(roi.reshape(1, 128, 128, 3))\n",
        "                pred_array = np.int8(prediction == prediction.max())\n",
        "                cv2.putText(image, return_letter(pred_array), (125, 50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (0,0,0), 2)\n",
        "                # print(pred_array)\n",
        "\n",
        "            # cv2.imshow('Testing', cv2.flip(roi, 1))\n",
        "            cv2.imshow('Testing', image)\n",
        "            i += 1\n",
        "            if cv2.waitKey(25) & 0xFF == ord(' '):\n",
        "                break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "01e71244e37f0f935b46186e5813adf1a869bae99bc7d264ff5e1ed5c924a01b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
